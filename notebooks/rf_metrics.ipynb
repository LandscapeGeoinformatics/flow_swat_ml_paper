{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75840be9-dac8-4a70-ace3-d1d75d508bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import seaborn as sns\n",
    "from hydroeval import evaluator, nse\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4bc24aa-103d-456c-baad-9553187a1924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set project directory\n",
    "def set_project_dir():\n",
    "    try:\n",
    "        os.chdir(r'\\\\export.hpc.ut.ee\\gis\\flow_swat_ml_paper')\n",
    "    except OSError:\n",
    "        os.chdir('D:/flow_swat_ml_paper')\n",
    "\n",
    "\n",
    "# Get Excel file based on country code\n",
    "def get_excel_file(country_code: str) -> str:\n",
    "    return f'ml/{country_code}/source_data/{country_code}.xlsx'\n",
    "\n",
    "\n",
    "# Add missing dates to DataFrame\n",
    "def add_missing_dates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    min_date = df['Date'].min().strftime('%Y-%m-%d')\n",
    "    max_date = df['Date'].max().strftime('%Y-%m-%d')\n",
    "    index = pd.date_range(min_date, max_date)\n",
    "    df = df.set_index('Date').reindex(index, fill_value=np.nan)\n",
    "    df = df.reset_index().rename(columns={'index': 'Date'})\n",
    "    return df\n",
    "\n",
    "\n",
    "# Get aggregation function based on time interval\n",
    "def get_agg_func(variable: str, time_interval: str):\n",
    "    if variable in ['Q', 'Tmax', 'Tmin']:\n",
    "        return 'mean'\n",
    "    elif variable == 'Pcp':\n",
    "        if time_interval.lower() == 'd':\n",
    "            return 'mean'\n",
    "        elif time_interval.lower() == 'm':\n",
    "            return 'sum'\n",
    "\n",
    "\n",
    "# Read flow data from Excel file\n",
    "def read_flow_data(country_code: str, time_interval: str) -> pd.DataFrame:\n",
    "    excel_file = get_excel_file(country_code)\n",
    "    flow_df = pd.read_excel(excel_file, sheet_name='Flow')\n",
    "    flow_df = flow_df.dropna(subset=['Date']).reset_index(drop=True)\n",
    "    flow_df = add_missing_dates(flow_df)\n",
    "    variable = 'Q'\n",
    "    agg_func = get_agg_func(variable, time_interval)\n",
    "    flow_df = flow_df.set_index('Date')\n",
    "    flow_df = flow_df.resample(time_interval).agg(agg_func).reset_index().round(1)\n",
    "    flow_df = flow_df.rename(columns={flow_df.columns[1]: f'{variable}_{time_interval.lower()}'})\n",
    "    return flow_df\n",
    "\n",
    "\n",
    "# Read predictor variable data from Excel file\n",
    "def read_pred_var_data(country_code: str, time_interval: str, na_values=None) -> pd.DataFrame:\n",
    "    excel_file = get_excel_file(country_code)\n",
    "    sheet_names = load_workbook(excel_file, read_only=True).sheetnames\n",
    "    pred_var_df_list = []\n",
    "    invalid_df_list = []\n",
    "    variables = ['Pcp', 'Tmax', 'Tmin']\n",
    "    for sheet_name in sheet_names:\n",
    "        if sheet_name != 'Flow':\n",
    "            df = pd.read_excel(excel_file, sheet_name=sheet_name, na_values=na_values)\n",
    "            df = df.rename(\n",
    "                columns={df.columns[1]: variables[0], df.columns[2]: variables[1], df.columns[3]: variables[2]}\n",
    "            )\n",
    "            df = df.dropna(subset=['Date']).reset_index(drop=True)\n",
    "            df = add_missing_dates(df)\n",
    "            df['Station'] = sheet_name\n",
    "            # Get indices of dates with invalid minimum temperature values\n",
    "            indices = df.loc[df['Tmax'] < df['Tmin']].index\n",
    "            # Replace temperature values on those dates with NaN\n",
    "            if len(indices) > 0:\n",
    "                invalid_df_list.append(df.loc[indices])\n",
    "                df.loc[indices, 'Tmax'] = np.nan\n",
    "                df.loc[indices, 'Tmin'] = np.nan\n",
    "            df = df.set_index('Date')\n",
    "            # Fill missing temperature values\n",
    "            if df['Tmax'].isna().sum() > 0:\n",
    "                df['Tmax'] = df['Tmax'].interpolate('time')\n",
    "            if df['Tmin'].isna().sum() > 0:\n",
    "                df['Tmin'] = df['Tmin'].interpolate('time')\n",
    "            agg_func_dict = {}\n",
    "            column_name_dict = {}\n",
    "            for variable in variables:\n",
    "                agg_func_dict[variable] = get_agg_func(variable, time_interval)\n",
    "                column_name_dict[variable] = f'{variable}_{time_interval}'\n",
    "            df = df.resample(time_interval).agg(agg_func_dict).reset_index().round(1)\n",
    "            df = df.rename(columns=column_name_dict)\n",
    "            pred_var_df_list.append(df)\n",
    "    if len(invalid_df_list) > 0:\n",
    "        invalid_df = pd.concat(invalid_df_list).reset_index(drop=True)\n",
    "        invalid_df.to_csv(f'ml/{country_code}/source_data/{country_code}_Tmin_invalid.csv', index=False)\n",
    "    pred_var_df = pd.concat(pred_var_df_list).groupby('Date').agg('mean').reset_index().round(1)\n",
    "    return pred_var_df\n",
    "\n",
    "\n",
    "# Get DataFrame with lags\n",
    "def calc_lags(\n",
    "        df: pd.DataFrame, variables: List[str], time_interval: str, lag_width: int, n_lags: int\n",
    ") -> pd.DataFrame:\n",
    "    lags = df.copy()\n",
    "    for variable in variables:\n",
    "        for i in range(1, lag_width + n_lags, lag_width):\n",
    "            lags[f'{variable}_{time_interval}-{i}'] = lags[f'{variable}_{time_interval}'].shift(i)\n",
    "    return lags\n",
    "\n",
    "\n",
    "# Get number of lags based on time interval\n",
    "def get_n_lags(time_interval: str) -> int:\n",
    "    if time_interval.lower() == 'd':\n",
    "        return 28\n",
    "    elif time_interval.lower() == 'm':\n",
    "        return 12\n",
    "\n",
    "\n",
    "# Get DataFrame with rolling aggregates\n",
    "def calc_rolling_aggs(\n",
    "        df: pd.DataFrame, variables: List[str], time_interval: str, window_width: int, n_windows: int,\n",
    "        agg_func_list: List[str]\n",
    ") -> pd.DataFrame:\n",
    "    rolling_aggs = df.copy()\n",
    "    for variable in variables:\n",
    "        for i in range(window_width, window_width * n_windows + window_width, window_width):\n",
    "            for agg_func in agg_func_list:\n",
    "                agg_col = f'{variable}_{time_interval}-{i}_rolling_{agg_func}'\n",
    "                rolling_aggs[agg_col] = rolling_aggs[f'{variable}_{time_interval}'].rolling(i).agg(agg_func).round(1)\n",
    "    return rolling_aggs\n",
    "\n",
    "\n",
    "# Get window width based on time interval\n",
    "def get_window_width(time_interval: str) -> int:\n",
    "    if time_interval.lower() == 'd':\n",
    "        return 7\n",
    "    elif time_interval.lower() == 'm':\n",
    "        return 3\n",
    "\n",
    "\n",
    "# Get DataFrame with leads\n",
    "def calc_leads(\n",
    "        df: pd.DataFrame, variables: List[str], time_interval: str, lead_width: int, n_leads: int\n",
    ") -> pd.DataFrame:\n",
    "    leads = df.copy()\n",
    "    for variable in variables:\n",
    "        for i in range(1, lead_width + n_leads, lead_width):\n",
    "            leads[f'{variable}_{time_interval}+{i}'] = leads[f'{variable}_{time_interval}'].shift(-i)\n",
    "    return leads\n",
    "\n",
    "\n",
    "# Get path of model directory\n",
    "def get_model_dir(country_code: str, target: str, feat_set: str) -> str:\n",
    "    model_dir = f'ml/{country_code}/models/rf/{country_code}_{target}_{feat_set}'\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    return model_dir\n",
    "\n",
    "\n",
    "# Get catchment name based on country code\n",
    "def get_catchment_name(country_code: str) -> str:\n",
    "    if country_code == 'ESP':\n",
    "        return 'Argos'\n",
    "    elif country_code == 'EST':\n",
    "        return 'PorijÃµgi'\n",
    "    elif country_code == 'ETH':\n",
    "        return 'Rib'\n",
    "    elif country_code == 'USA':\n",
    "        return 'Bald Eagle'\n",
    "\n",
    "\n",
    "# Get target based on feature set\n",
    "def get_target(feat_set: str) -> str:\n",
    "    time_interval = feat_set[-1]\n",
    "    if time_interval == 'd':\n",
    "        return f'Q_{time_interval}+1'\n",
    "    elif time_interval == 'm':\n",
    "        return f'Q_{time_interval}+1'\n",
    "\n",
    "\n",
    "# Get feature set list based on target\n",
    "def get_feat_set(target: str) -> str:\n",
    "    if target == 'Q_d+1':\n",
    "        return ['FS1_d', 'FS2_d', 'FS3_d']\n",
    "    elif target == 'Q_m+1':\n",
    "        return ['FS1_m', 'FS2_m', 'FS3_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ccd42c4-4faf-4ab4-b30c-b84f903a930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory\n",
    "working_dir = r'\\\\export.hpc.ut.ee\\gis\\flow_swat_ml_paper'\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f5fe48-1dc6-4afe-9691-2afabe4669b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = 'swat/SWAT_results.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5239d5-ca22-4e32-8e18-04dea88c4621",
   "metadata": {},
   "source": [
    "# Daily models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abd01074-d81a-4429-840d-06fa16dd8f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Q_d+1'\n",
    "country_codes = ['ESP', 'EST', 'ETH', 'USA']\n",
    "feat_set_list = ['FS1_d', 'FS2_d', 'FS3_d']\n",
    "# test_size_list = [0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "test_size_list = [0.5]\n",
    "time_interval = 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d74bff-79f3-4f96-8f9d-11b0594336e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "\n",
    "for country_code in country_codes:\n",
    "    \n",
    "    # Read SWAT results\n",
    "    sheet_name = f'{country_code}_{time_interval}'\n",
    "    swat_results = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "\n",
    "    # Get start and end of SWAT time series\n",
    "    swat_min_date = swat_results[swat_results.columns[0]].min()\n",
    "    swat_max_date = swat_results[swat_results.columns[0]].max()\n",
    "    \n",
    "    for feat_set in feat_set_list:\n",
    "        model_dir = get_model_dir(country_code, target, feat_set)\n",
    "        \n",
    "        for test_size in test_size_list:\n",
    "            test_size_int = test_size_int = int(test_size * 100)\n",
    "\n",
    "            # Get indices of training samples\n",
    "            train_indices = pd.read_csv(\n",
    "                f'{model_dir}/{country_code}_{target}_{feat_set}_feat_train_{test_size_int}.csv', usecols=['Index']\n",
    "            )['Index'].values\n",
    "\n",
    "            # Get indices of test samples\n",
    "            test_indices = pd.read_csv(\n",
    "                f'{model_dir}/{country_code}_{target}_{feat_set}_feat_test_{test_size_int}.csv', usecols=['Index']\n",
    "            )['Index'].values\n",
    "\n",
    "            # Read RF results\n",
    "            obs_vs_pred = pd.read_csv(f'{model_dir}/{country_code}_{target}_{feat_set}_obs_vs_pred_{test_size_int}.csv', parse_dates=['Date'])\n",
    "            obs_vs_pred['Index'] = obs_vs_pred.index\n",
    "\n",
    "            # Drop rows outside of the SWAT study period\n",
    "            obs_vs_pred = obs_vs_pred.loc[(swat_min_date <= obs_vs_pred['Date']) & (obs_vs_pred['Date'] <= swat_max_date)]\n",
    "\n",
    "            # Training set\n",
    "            end_index_train = train_indices[-1]\n",
    "            obs_vs_pred_train = obs_vs_pred.loc[:end_index_train, :]\n",
    "            obs_train = obs_vs_pred_train[target]\n",
    "            pred_train = obs_vs_pred_train[f'{target}_pred']\n",
    "            rmse_train = round(mean_squared_error(obs_train, pred_train, squared=False), 2)\n",
    "            r2_train = round(r2_score(obs_train, pred_train), 2)\n",
    "            nse_train = round(evaluator(nse, pred_train, obs_train)[0], 2)\n",
    "\n",
    "            # Test set\n",
    "            start_index_test = test_indices[0]\n",
    "            obs_vs_pred_test = obs_vs_pred.loc[start_index_test:, :]\n",
    "            obs_test = obs_vs_pred_test[target]\n",
    "            pred_test = obs_vs_pred_test[f'{target}_pred']\n",
    "            rmse_test = round(mean_squared_error(obs_test, pred_test, squared=False), 2)\n",
    "            r2_test = round(r2_score(obs_test, pred_test), 2)\n",
    "            nse_test = round(evaluator(nse, pred_test, obs_test)[0], 2)\n",
    "\n",
    "            # Append results to list\n",
    "            results = {\n",
    "                'country_code': country_code,\n",
    "                'target': target,\n",
    "                'feat_set': feat_set,\n",
    "                'model_version': f'{target}_{feat_set}',\n",
    "                'test_size_int': test_size_int,\n",
    "                'nse_train': nse_train,\n",
    "                'nse_test': nse_test,\n",
    "                'rmse_train': rmse_train,\n",
    "                'rmse_test': rmse_test,\n",
    "                'r2_train': r2_train,\n",
    "                'r2_test': r2_test\n",
    "            }\n",
    "            df_results = pd.DataFrame([results.values()], columns=results.keys())\n",
    "            results_list.append(df_results)\n",
    "results_df = pd.concat(results_list).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a83f97e-62c6-4ae3-a6c2-6fc789430c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>target</th>\n",
       "      <th>feat_set</th>\n",
       "      <th>model_version</th>\n",
       "      <th>test_size_int</th>\n",
       "      <th>nse_train</th>\n",
       "      <th>nse_test</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>rmse_test</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESP</td>\n",
       "      <td>Q_d+1</td>\n",
       "      <td>FS1_d</td>\n",
       "      <td>Q_d+1_FS1_d</td>\n",
       "      <td>50</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESP</td>\n",
       "      <td>Q_d+1</td>\n",
       "      <td>FS2_d</td>\n",
       "      <td>Q_d+1_FS2_d</td>\n",
       "      <td>50</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESP</td>\n",
       "      <td>Q_d+1</td>\n",
       "      <td>FS3_d</td>\n",
       "      <td>Q_d+1_FS3_d</td>\n",
       "      <td>50</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EST</td>\n",
       "      <td>Q_d+1</td>\n",
       "      <td>FS1_d</td>\n",
       "      <td>Q_d+1_FS1_d</td>\n",
       "      <td>50</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EST</td>\n",
       "      <td>Q_d+1</td>\n",
       "      <td>FS2_d</td>\n",
       "      <td>Q_d+1_FS2_d</td>\n",
       "      <td>50</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EST</td>\n",
       "      <td>Q_d+1</td>\n",
       "      <td>FS3_d</td>\n",
       "      <td>Q_d+1_FS3_d</td>\n",
       "      <td>50</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ETH</td>\n",
       "      <td>Q_d+1</td>\n",
       "      <td>FS1_d</td>\n",
       "      <td>Q_d+1_FS1_d</td>\n",
       "      <td>50</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2.81</td>\n",
       "      <td>10.74</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ETH</td>\n",
       "      <td>Q_d+1</td>\n",
       "      <td>FS2_d</td>\n",
       "      <td>Q_d+1_FS2_d</td>\n",
       "      <td>50</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3.30</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ETH</td>\n",
       "      <td>Q_d+1</td>\n",
       "      <td>FS3_d</td>\n",
       "      <td>Q_d+1_FS3_d</td>\n",
       "      <td>50</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2.89</td>\n",
       "      <td>8.49</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>USA</td>\n",
       "      <td>Q_d+1</td>\n",
       "      <td>FS1_d</td>\n",
       "      <td>Q_d+1_FS1_d</td>\n",
       "      <td>50</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>4.92</td>\n",
       "      <td>17.62</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>USA</td>\n",
       "      <td>Q_d+1</td>\n",
       "      <td>FS2_d</td>\n",
       "      <td>Q_d+1_FS2_d</td>\n",
       "      <td>50</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.91</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>USA</td>\n",
       "      <td>Q_d+1</td>\n",
       "      <td>FS3_d</td>\n",
       "      <td>Q_d+1_FS3_d</td>\n",
       "      <td>50</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.51</td>\n",
       "      <td>4.30</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country_code target feat_set model_version  test_size_int  nse_train  \\\n",
       "0           ESP  Q_d+1    FS1_d   Q_d+1_FS1_d             50       0.90   \n",
       "1           ESP  Q_d+1    FS2_d   Q_d+1_FS2_d             50       0.92   \n",
       "2           ESP  Q_d+1    FS3_d   Q_d+1_FS3_d             50       0.90   \n",
       "3           EST  Q_d+1    FS1_d   Q_d+1_FS1_d             50       0.99   \n",
       "4           EST  Q_d+1    FS2_d   Q_d+1_FS2_d             50       0.99   \n",
       "5           EST  Q_d+1    FS3_d   Q_d+1_FS3_d             50       0.99   \n",
       "6           ETH  Q_d+1    FS1_d   Q_d+1_FS1_d             50       0.99   \n",
       "7           ETH  Q_d+1    FS2_d   Q_d+1_FS2_d             50       0.98   \n",
       "8           ETH  Q_d+1    FS3_d   Q_d+1_FS3_d             50       0.99   \n",
       "9           USA  Q_d+1    FS1_d   Q_d+1_FS1_d             50       0.91   \n",
       "10          USA  Q_d+1    FS2_d   Q_d+1_FS2_d             50       0.91   \n",
       "11          USA  Q_d+1    FS3_d   Q_d+1_FS3_d             50       0.93   \n",
       "\n",
       "    nse_test  rmse_train  rmse_test  r2_train  r2_test  \n",
       "0      -0.01        0.15       0.65      0.90    -0.01  \n",
       "1       0.20        0.14       0.58      0.92     0.20  \n",
       "2       0.24        0.15       0.57      0.90     0.24  \n",
       "3      -0.67        0.25       1.54      0.99    -0.67  \n",
       "4       0.82        0.23       0.50      0.99     0.82  \n",
       "5       0.85        0.23       0.46      0.99     0.85  \n",
       "6       0.81        2.81      10.74      0.99     0.81  \n",
       "7       0.88        3.30       8.50      0.98     0.88  \n",
       "8       0.88        2.89       8.49      0.99     0.88  \n",
       "9      -1.02        4.92      17.62      0.91    -1.02  \n",
       "10      0.50        4.91       8.80      0.91     0.50  \n",
       "11      0.51        4.30       8.72      0.93     0.51  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4e93c51-f22c-42fb-b1a8-3e1b10dfa5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(fr'\\\\export.hpc.ut.ee\\gis\\flow_swat_ml_paper\\ml\\{target}_rf_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6656d-9432-4c4f-ad29-f4ce2f1e3e75",
   "metadata": {},
   "source": [
    "# Monthly models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84918ea6-9a09-4c11-8dd7-fc3e8e0767d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Q_m+1'\n",
    "country_codes = ['ESP', 'EST', 'ETH', 'USA']\n",
    "feat_set_list = ['FS1_m', 'FS2_m', 'FS3_m']\n",
    "# test_size_list = [0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "test_size_list = [0.5]\n",
    "time_interval = 'M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e22f0320-d4c0-4a17-ab31-ccae57b081a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESP\n",
      "2006-01-31 2010-12-31 2011-01-31 2016-12-31\n",
      "ESP\n",
      "2006-01-31 2010-12-31 2011-01-31 2016-12-31\n",
      "ESP\n",
      "2006-01-31 2010-12-31 2011-01-31 2016-12-31\n",
      "EST\n",
      "2009-01-31 2013-12-31 2014-01-31 2019-12-31\n",
      "EST\n",
      "2009-01-31 2013-12-31 2014-01-31 2019-12-31\n",
      "EST\n",
      "2009-01-31 2013-12-31 2014-01-31 2019-12-31\n",
      "ETH\n",
      "1997-01-31 2001-12-31 2002-01-31 2007-12-31\n",
      "ETH\n",
      "1997-01-31 2001-12-31 2002-01-31 2007-12-31\n",
      "ETH\n",
      "1997-01-31 2001-12-31 2002-01-31 2007-12-31\n",
      "USA\n",
      "2002-01-31 2006-12-31 2007-01-31 2012-12-31\n",
      "USA\n",
      "2002-01-31 2006-12-31 2007-01-31 2012-12-31\n",
      "USA\n",
      "2002-01-31 2006-12-31 2007-01-31 2012-12-31\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "for country_code in country_codes:\n",
    "    \n",
    "    # Read SWAT results\n",
    "    sheet_name = f'{country_code}_{time_interval}'\n",
    "    swat_results = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "    \n",
    "    # Shift date to the end of the month to match with RF time series\n",
    "    swat_results[swat_results.columns[0]] = swat_results[swat_results.columns[0]] + pd.offsets.MonthEnd(0)\n",
    "\n",
    "    # Get start and end of SWAT time series\n",
    "    swat_min_date = swat_results[swat_results.columns[0]].min()\n",
    "    swat_max_date = swat_results[swat_results.columns[0]].max()\n",
    "    \n",
    "    for feat_set in feat_set_list:\n",
    "        model_dir = get_model_dir(country_code, target, feat_set)\n",
    "        \n",
    "        for test_size in test_size_list:\n",
    "            test_size_int = test_size_int = int(test_size * 100)\n",
    "\n",
    "            # Get indices of training samples\n",
    "            train_indices = pd.read_csv(\n",
    "                f'{model_dir}/{country_code}_{target}_{feat_set}_feat_train_{test_size_int}.csv', usecols=['Index']\n",
    "            )['Index'].values\n",
    "\n",
    "            # Get indices of test samples\n",
    "            test_indices = pd.read_csv(\n",
    "                f'{model_dir}/{country_code}_{target}_{feat_set}_feat_test_{test_size_int}.csv', usecols=['Index']\n",
    "            )['Index'].values\n",
    "\n",
    "            # Read RF results\n",
    "            obs_vs_pred = pd.read_csv(f'{model_dir}/{country_code}_{target}_{feat_set}_obs_vs_pred_{test_size_int}.csv', parse_dates=['Date'])\n",
    "            obs_vs_pred['Index'] = obs_vs_pred.index\n",
    "\n",
    "            # Drop rows outside of the SWAT study period\n",
    "            obs_vs_pred = obs_vs_pred.loc[(swat_min_date <= obs_vs_pred['Date']) & (obs_vs_pred['Date'] <= swat_max_date)]\n",
    "\n",
    "            # Training set\n",
    "            end_index_train = train_indices[-1]\n",
    "            obs_vs_pred_train = obs_vs_pred.loc[:end_index_train, :]\n",
    "            \n",
    "            obs_vs_pred_train = obs_vs_pred_train.loc[(swat_min_date <= obs_vs_pred_train['Date']) & (obs_vs_pred_train['Date'] <= swat_max_date)]\n",
    "            \n",
    "            rf_train_min_date = obs_vs_pred_train['Date'].dt.strftime('%Y-%m-%d').min()\n",
    "            rf_train_max_date = obs_vs_pred_train['Date'].dt.strftime('%Y-%m-%d').max()\n",
    "            \n",
    "            obs_train = obs_vs_pred_train[target]\n",
    "            pred_train = obs_vs_pred_train[f'{target}_pred']\n",
    "            rmse_train = round(mean_squared_error(obs_train, pred_train, squared=False), 2)\n",
    "            r2_train = round(r2_score(obs_train, pred_train), 2)\n",
    "            nse_train = round(evaluator(nse, pred_train, obs_train)[0], 2)\n",
    "\n",
    "            # Test set\n",
    "            start_index_test = test_indices[0]\n",
    "            obs_vs_pred_test = obs_vs_pred.loc[start_index_test:, :]\n",
    "            \n",
    "            obs_vs_pred_test = obs_vs_pred_test.loc[(swat_min_date <= obs_vs_pred_test['Date']) & (obs_vs_pred_test['Date'] <= swat_max_date)]\n",
    "            \n",
    "            rf_test_min_date = obs_vs_pred_test['Date'].dt.strftime('%Y-%m-%d').min()\n",
    "            rf_test_max_date = obs_vs_pred_test['Date'].dt.strftime('%Y-%m-%d').max()\n",
    "            \n",
    "            obs_test = obs_vs_pred_test[target]\n",
    "            pred_test = obs_vs_pred_test[f'{target}_pred']\n",
    "            rmse_test = round(mean_squared_error(obs_test, pred_test, squared=False), 2)\n",
    "            r2_test = round(r2_score(obs_test, pred_test), 2)\n",
    "            nse_test = round(evaluator(nse, pred_test, obs_test)[0], 2)\n",
    "            \n",
    "            print(country_code)\n",
    "            print(rf_train_min_date, rf_train_max_date, rf_test_min_date, rf_test_max_date)\n",
    "\n",
    "            # Append results to list\n",
    "            results = {\n",
    "                'country_code': country_code,\n",
    "                'target': target,\n",
    "                'feat_set': feat_set,\n",
    "                'model_version': f'{target}_{feat_set}',\n",
    "                'test_size_int': test_size_int,\n",
    "                'nse_train': nse_train,\n",
    "                'nse_test': nse_test,\n",
    "                'rmse_train': rmse_train,\n",
    "                'rmse_test': rmse_test,\n",
    "                'r2_train': r2_train,\n",
    "                'r2_test': r2_test\n",
    "            }\n",
    "            df_results = pd.DataFrame([results.values()], columns=results.keys())\n",
    "            results_list.append(df_results)\n",
    "results_df = pd.concat(results_list).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07a599dd-8e78-4fd8-b362-08d71efbff41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>target</th>\n",
       "      <th>feat_set</th>\n",
       "      <th>model_version</th>\n",
       "      <th>test_size_int</th>\n",
       "      <th>nse_train</th>\n",
       "      <th>nse_test</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>rmse_test</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESP</td>\n",
       "      <td>Q_m+1</td>\n",
       "      <td>FS1_m</td>\n",
       "      <td>Q_m+1_FS1_m</td>\n",
       "      <td>50</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESP</td>\n",
       "      <td>Q_m+1</td>\n",
       "      <td>FS2_m</td>\n",
       "      <td>Q_m+1_FS2_m</td>\n",
       "      <td>50</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESP</td>\n",
       "      <td>Q_m+1</td>\n",
       "      <td>FS3_m</td>\n",
       "      <td>Q_m+1_FS3_m</td>\n",
       "      <td>50</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EST</td>\n",
       "      <td>Q_m+1</td>\n",
       "      <td>FS1_m</td>\n",
       "      <td>Q_m+1_FS1_m</td>\n",
       "      <td>50</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EST</td>\n",
       "      <td>Q_m+1</td>\n",
       "      <td>FS2_m</td>\n",
       "      <td>Q_m+1_FS2_m</td>\n",
       "      <td>50</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EST</td>\n",
       "      <td>Q_m+1</td>\n",
       "      <td>FS3_m</td>\n",
       "      <td>Q_m+1_FS3_m</td>\n",
       "      <td>50</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ETH</td>\n",
       "      <td>Q_m+1</td>\n",
       "      <td>FS1_m</td>\n",
       "      <td>Q_m+1_FS1_m</td>\n",
       "      <td>50</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.87</td>\n",
       "      <td>4.35</td>\n",
       "      <td>7.74</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ETH</td>\n",
       "      <td>Q_m+1</td>\n",
       "      <td>FS2_m</td>\n",
       "      <td>Q_m+1_FS2_m</td>\n",
       "      <td>50</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3.47</td>\n",
       "      <td>10.43</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ETH</td>\n",
       "      <td>Q_m+1</td>\n",
       "      <td>FS3_m</td>\n",
       "      <td>Q_m+1_FS3_m</td>\n",
       "      <td>50</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3.58</td>\n",
       "      <td>7.44</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>USA</td>\n",
       "      <td>Q_m+1</td>\n",
       "      <td>FS1_m</td>\n",
       "      <td>Q_m+1_FS1_m</td>\n",
       "      <td>50</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.58</td>\n",
       "      <td>6.53</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>USA</td>\n",
       "      <td>Q_m+1</td>\n",
       "      <td>FS2_m</td>\n",
       "      <td>Q_m+1_FS2_m</td>\n",
       "      <td>50</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2.59</td>\n",
       "      <td>7.06</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>USA</td>\n",
       "      <td>Q_m+1</td>\n",
       "      <td>FS3_m</td>\n",
       "      <td>Q_m+1_FS3_m</td>\n",
       "      <td>50</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.84</td>\n",
       "      <td>6.46</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country_code target feat_set model_version  test_size_int  nse_train  \\\n",
       "0           ESP  Q_m+1    FS1_m   Q_m+1_FS1_m             50       0.91   \n",
       "1           ESP  Q_m+1    FS2_m   Q_m+1_FS2_m             50       0.92   \n",
       "2           ESP  Q_m+1    FS3_m   Q_m+1_FS3_m             50       0.92   \n",
       "3           EST  Q_m+1    FS1_m   Q_m+1_FS1_m             50       0.91   \n",
       "4           EST  Q_m+1    FS2_m   Q_m+1_FS2_m             50       0.91   \n",
       "5           EST  Q_m+1    FS3_m   Q_m+1_FS3_m             50       0.91   \n",
       "6           ETH  Q_m+1    FS1_m   Q_m+1_FS1_m             50       0.96   \n",
       "7           ETH  Q_m+1    FS2_m   Q_m+1_FS2_m             50       0.98   \n",
       "8           ETH  Q_m+1    FS3_m   Q_m+1_FS3_m             50       0.97   \n",
       "9           USA  Q_m+1    FS1_m   Q_m+1_FS1_m             50       0.89   \n",
       "10          USA  Q_m+1    FS2_m   Q_m+1_FS2_m             50       0.89   \n",
       "11          USA  Q_m+1    FS3_m   Q_m+1_FS3_m             50       0.87   \n",
       "\n",
       "    nse_test  rmse_train  rmse_test  r2_train  r2_test  \n",
       "0       0.27        0.09       0.28      0.91     0.27  \n",
       "1       0.34        0.08       0.27      0.92     0.34  \n",
       "2       0.38        0.08       0.26      0.92     0.38  \n",
       "3       0.13        0.52       0.82      0.91     0.13  \n",
       "4       0.01        0.50       0.88      0.91     0.01  \n",
       "5       0.05        0.51       0.86      0.91     0.05  \n",
       "6       0.87        4.35       7.74      0.96     0.87  \n",
       "7       0.76        3.47      10.43      0.98     0.76  \n",
       "8       0.88        3.58       7.44      0.97     0.88  \n",
       "9       0.29        2.58       6.53      0.89     0.29  \n",
       "10      0.18        2.59       7.06      0.89     0.18  \n",
       "11      0.31        2.84       6.46      0.87     0.31  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0b22b0f-d277-4edd-b7a8-02a09031e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(fr'\\\\export.hpc.ut.ee\\gis\\flow_swat_ml_paper\\ml\\{target}_rf_metrics.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydro",
   "language": "python",
   "name": "hydro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
